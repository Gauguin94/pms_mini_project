# app_streamlit.py
from __future__ import annotations

import os
import time
import pymysql
import pandas as pd
import matplotlib.pyplot as plt
import streamlit as st
from dotenv import load_dotenv

# -----------------------------
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ & DB ì„¤ì •
# -----------------------------
load_dotenv()

DB_CFG = dict(
    host=os.getenv("DB_HOST", "127.0.0.1"),
    port=int(os.getenv("DB_PORT", "3306")),
    user=os.getenv("DB_USER", "pms"),
    password=os.getenv("DB_PASSWORD", ""),
    database=os.getenv("DB_NAME", "pms"),
    cursorclass=pymysql.cursors.DictCursor,
)

# -----------------------------
# ì»¤ë„¥ì…˜ ìºì‹œ & ì¿¼ë¦¬ ìœ í‹¸
# -----------------------------
@st.cache_resource(show_spinner=False)
def get_conn():
    # ìºì‹œëœ ë‹¨ì¼ ì»¤ë„¥ì…˜ì„ ì¬ì‚¬ìš© (ë‹«ì§€ ë§ˆì„¸ìš”!)
    return pymysql.connect(**DB_CFG)

def q(sql: str, args=None):
    """ë‹«ì§€ ì•ŠëŠ” ì»¤ë„¥ì…˜ìœ¼ë¡œ ì¿¼ë¦¬; ëŠê¸°ë©´ ì¬ì—°ê²° í›„ ì¬ì‹œë„."""
    conn = get_conn()
    try:
        conn.ping(reconnect=True)
        with conn.cursor() as cur:
            cur.execute(sql, args or ())
            return cur.fetchall()
    except Exception:
        # ìºì‹œ ë¬´íš¨í™” í›„ ì¬ì—°ê²°
        get_conn.clear()
        conn = get_conn()
        conn.ping(reconnect=True)
        with conn.cursor() as cur:
            cur.execute(sql, args or ())
            return cur.fetchall()

@st.cache_data(ttl=30)
def table_columns(tbl: str):
    rows = q(f"SHOW COLUMNS FROM {tbl};")
    return [r["Field"] for r in rows]

# -----------------------------
# í˜ì´ì§€ ì„¤ì • & ì‚¬ì´ë“œë°”
# -----------------------------
st.set_page_config(page_title="PMS Monitoring", layout="wide")
st.title("PMS Monitoring Dashboard")

with st.sidebar:
    st.subheader("Controls")
    if st.button("ğŸ”„ Refresh now"):
        st.experimental_rerun()
    auto_sec = st.number_input("Auto refresh every (sec)", min_value=0, max_value=300, value=0, step=5)

if auto_sec and auto_sec > 0:
    last = st.session_state.get("_last_refresh_ts", 0.0)
    now = time.time()
    if now - last >= auto_sec:
        st.session_state["_last_refresh_ts"] = now
        st.experimental_rerun()

# -----------------------------
# íƒ­ êµ¬ì„±
# -----------------------------
tab1, tab2, tab3 = st.tabs(["ğŸ“Š Dashboard", "ğŸ” Retrain", "ğŸ“š History"])

# =========================================================
# ğŸ“Š Dashboard íƒ­
# =========================================================
with tab1:
    # ===== Realtime Charts (ìƒë‹¨) =====
    st.subheader("Realtime Signals")

    MAX_POINTS = int(os.getenv("REALTIME_MAX_POINTS", "5000"))
    cols = table_columns("realtime_table")

    need_cols = ["time_rms", "fft_over_env"]
    missing = [c for c in need_cols if c not in cols]
    if missing:
        st.error(f"`realtime_table`ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing)}")
    else:
        # xì¶• í›„ë³´ëŠ” ê·¸ëŒ€ë¡œ ë‘ë˜, ì¶• ë¼ë²¨ í…ìŠ¤íŠ¸ëŠ” ê³ ì •("time", "frequency")
        time_candidates = ["time", "created_at", "ts", "timestamp", "dt"]
        freq_candidates = ["frequency", "freq", "fft_frequency", "fft_freq", "hz"]

        time_col = next((c for c in time_candidates if c in cols), None)
        freq_col = next((c for c in freq_candidates if c in cols), None)

        # SELECT ì»¬ëŸ¼ (ì¡´ì¬í•˜ëŠ” ê²ƒë§Œ)
        select_cols = []
        if time_col: select_cols.append(f"`{time_col}`")
        if freq_col: select_cols.append(f"`{freq_col}`")
        select_cols += ["`time_rms`", "`fft_over_env`"]
        select_sql = ", ".join(select_cols)

        # ì •ë ¬ ìš°ì„ ìˆœìœ„: time_col â†’ ê·¸ ì™¸ í›„ë³´
        sort_candidates = ([time_col] if time_col else []) + ["created_at", "id", "ts", "timestamp", "time", "dt", "seq", "offset"]
        sort_col = next((c for c in sort_candidates if c and c in cols), None)

        sql = f"SELECT {select_sql} FROM realtime_table "
        if sort_col:
            sql += f"ORDER BY `{sort_col}` ASC "
        sql += f"LIMIT {MAX_POINTS};"

        rows_rt = q(sql)

        if not rows_rt:
            st.info("realtime_table ë¹„ì–´ìˆìŒ")
        else:
            df_rt = pd.DataFrame(rows_rt)

            # ì¢Œ: x_time (ê°€ëŠ¥í•˜ë©´ time ê³„ì—´ì„ datetimeìœ¼ë¡œ), ì—†ìœ¼ë©´ index
            if time_col and time_col in df_rt.columns:
                df_rt[time_col] = pd.to_datetime(df_rt[time_col], errors="coerce")
                x_time = df_rt[time_col]
            else:
                x_time = pd.RangeIndex(start=0, stop=len(df_rt))

            # ìš°: x_freq (ê°€ëŠ¥í•˜ë©´ frequencyë¥¼ numericìœ¼ë¡œ), ì—†ìœ¼ë©´ index
            if freq_col and freq_col in df_rt.columns:
                df_rt[freq_col] = pd.to_numeric(df_rt[freq_col], errors="coerce")
                x_freq = df_rt[freq_col]
            else:
                x_freq = pd.RangeIndex(start=0, stop=len(df_rt))

            # yê°’ ìˆ«ìí™” & NaN ì œê±°
            df_rt["time_rms"] = pd.to_numeric(df_rt["time_rms"], errors="coerce")
            df_rt["fft_over_env"] = pd.to_numeric(df_rt["fft_over_env"], errors="coerce")
            valid = df_rt["time_rms"].notna() & df_rt["fft_over_env"].notna()
            if time_col and time_col in df_rt.columns:
                valid &= df_rt[time_col].notna()
            if freq_col and freq_col in df_rt.columns:
                valid &= df_rt[freq_col].notna()
            df_rt = df_rt[valid].reset_index(drop=True)

            # í•„í„° í›„ xì¶• ì¬ì§€ì •
            if time_col and time_col in df_rt.columns:
                x_time = df_rt[time_col]
            else:
                x_time = pd.RangeIndex(start=0, stop=len(df_rt))
            if freq_col and freq_col in df_rt.columns:
                x_freq = df_rt[freq_col]
            else:
                x_freq = pd.RangeIndex(start=0, stop=len(df_rt))

            c1, c2 = st.columns(2)

            # --- ì¢Œ: Vrms vs Time (Line + grid) ---
            with c1:
                st.markdown("**Vrms - Time Domain**")
                fig1 = plt.figure(figsize=(6, 3))
                plt.plot(x_time, df_rt["time_rms"])
                plt.xlabel("time")          # â† ì¶• ì´ë¦„ ê³ ì •
                plt.ylabel("Vrms")          # â† ì¶• ì´ë¦„ ê³ ì •
                plt.grid(True, linestyle="--", alpha=0.5)
                plt.tight_layout()
                st.pyplot(fig1)

            # --- ìš°: Amplitude vs Frequency (Stem + grid) ---
            with c2:
                st.markdown("**Amplitude Spectrum - Freq Domain**")
                fig2 = plt.figure(figsize=(6, 3))
                # í˜¸í™˜: use_line_collection ì¸ì ì—†ì´
                markerline, stemlines, baseline = plt.stem(x_freq, df_rt["fft_over_env"])
                try:
                    markerline.set_marker('.'); markerline.set_markersize(3)
                    baseline.set_linewidth(0.5)
                    try:
                        for l in stemlines:
                            l.set_linewidth(0.7)
                    except TypeError:
                        stemlines.set_linewidth(0.7)
                except Exception:
                    pass
                plt.xlabel("frequency")     # â† ì¶• ì´ë¦„ ê³ ì •
                plt.ylabel("Amplitude")     # â† ì¶• ì´ë¦„ ê³ ì •
                plt.grid(True, linestyle="--", alpha=0.5)
                plt.tight_layout()
                st.pyplot(fig2)

    st.divider()

    # ===== ìµœì‹  ISO / RAG ë‹µë³€ (í•˜ë‹¨ ì¹´ë“œ) =====
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Latest ISO Advice")
        rows = q("""
            SELECT id, offset_idx, mae, suspect, query, result_markdown, created_at
            FROM pms_ai_advice
            ORDER BY id DESC
            LIMIT 1;
        """)
        if rows:
            r = rows[0]
            st.caption(
                f"ID #{r['id']} Â· offset {r['offset_idx']} Â· "
                f"MAE {float(r['mae']):.3f} Â· {r.get('suspect') or '-'} Â· {r['created_at']}"
            )
            st.markdown(r.get("result_markdown") or "_(empty)_")
        else:
            st.info("No ISO advice yet.")

    with col2:
        st.subheader("Latest RAG Advice")
        rows = q("""
            SELECT id, offset_idx, mae, suspect, answer_md, created_at
            FROM pms_ai_rag_advice
            ORDER BY id DESC
            LIMIT 1;
        """)
        if rows:
            r = rows[0]
            st.caption(
                f"ID #{r['id']} Â· offset {r['offset_idx']} Â· "
                f"MAE {float(r['mae']):.3f} Â· {r.get('suspect') or '-'} Â· {r['created_at']}"
            )
            st.markdown(r.get("answer_md") or "_(empty)_")
        else:
            st.info("No RAG advice yet.")

# =========================================================
# ğŸ” Retrain íƒ­
# =========================================================
with tab2:
    st.subheader("Retrain Runs")

    runs = q("""
        SELECT id, started_at, ended_at, status, duration_sec, message
        FROM pms_retrain_log
        ORDER BY id DESC
        LIMIT 20;
    """)
    df = pd.DataFrame(runs)
    if not df.empty:
        st.dataframe(df, use_container_width=True, hide_index=True)
        sel = st.selectbox("Show details for log_id", df["id"].tolist())
        if sel:
            details = q("""
                SELECT seq, level, text, ts
                FROM pms_retrain_log_detail
                WHERE log_id=%s
                ORDER BY seq ASC;
            """, (sel,))
            st.write(f"### Log #{sel}")
            for d in details:
                st.markdown(f"- `{d['ts']}` **{d['level']}** Â· {d['text']}")
    else:
        st.info("No retrain logs yet.")

    st.divider()
    st.caption("ìˆ˜ë™ ì¬í•™ìŠµ íŠ¸ë¦¬ê±° (FastAPIê°€ /retrain ì œê³µ ì¤‘ì¼ ë•Œ)")
    api_url = os.getenv("API_RETRAIN_URL", "http://127.0.0.1:8001/retrain")
    if st.button("Run Retrain via API"):
        import requests
        try:
            r = requests.post(api_url, timeout=8)
            st.success(f"Triggered: {r.status_code} {r.text[:300]}")
        except Exception as e:
            st.error(f"Trigger failed: {e}")

# =========================================================
# ğŸ“š History íƒ­
# =========================================================
with tab3:
    st.subheader("ISO Advice History")
    rows = q("""
        SELECT id, offset_idx, mae, suspect,
               LEFT(result_markdown, 140) AS preview,
               created_at
        FROM pms_ai_advice
        ORDER BY id DESC
        LIMIT 100;
    """)
    st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)

    st.subheader("RAG Advice History")
    rows = q("""
        SELECT id, offset_idx, mae, suspect,
               LEFT(answer_md, 140) AS preview,
               created_at
        FROM pms_ai_rag_advice
        ORDER BY id DESC
        LIMIT 100;
    """)
    st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)


# from __future__ import annotations

# import os
# import time
# import pymysql
# import pandas as pd
# import matplotlib.pyplot as plt
# import streamlit as st
# from dotenv import load_dotenv

# # -----------------------------
# # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ & DB ì„¤ì •
# # -----------------------------
# load_dotenv()

# DB_CFG = dict(
#     host=os.getenv("DB_HOST", "127.0.0.1"),
#     port=int(os.getenv("DB_PORT", "3306")),
#     user=os.getenv("DB_USER", "pms"),
#     password=os.getenv("DB_PASSWORD", ""),
#     database=os.getenv("DB_NAME", "pms"),
#     cursorclass=pymysql.cursors.DictCursor,
# )

# # -----------------------------
# # ì»¤ë„¥ì…˜ ìºì‹œ & ì¿¼ë¦¬ ìœ í‹¸
# # -----------------------------
# @st.cache_resource(show_spinner=False)
# def get_conn():
#     # ìºì‹œëœ ë‹¨ì¼ ì»¤ë„¥ì…˜ì„ ì¬ì‚¬ìš© (ë‹«ì§€ ë§ ê²ƒ!)
#     return pymysql.connect(**DB_CFG)

# def q(sql: str, args=None):
#     """ë‹«ì§€ ì•ŠëŠ” ì»¤ë„¥ì…˜ìœ¼ë¡œ ì¿¼ë¦¬; ëŠê¸°ë©´ ì¬ì—°ê²° í›„ ì¬ì‹œë„."""
#     conn = get_conn()
#     try:
#         conn.ping(reconnect=True)
#         with conn.cursor() as cur:
#             cur.execute(sql, args or ())
#             return cur.fetchall()
#     except Exception:
#         # ìºì‹œ ë¬´íš¨í™” í›„ ì¬ì—°ê²°
#         get_conn.clear()
#         conn = get_conn()
#         conn.ping(reconnect=True)
#         with conn.cursor() as cur:
#             cur.execute(sql, args or ())
#             return cur.fetchall()

# @st.cache_data(ttl=30)
# def table_columns(tbl: str):
#     rows = q(f"SHOW COLUMNS FROM {tbl};")
#     return [r["Field"] for r in rows]

# # -----------------------------
# # í˜ì´ì§€ ì„¤ì • & ì‚¬ì´ë“œë°”
# # -----------------------------
# st.set_page_config(page_title="PMS Monitoring", layout="wide")
# st.title("PMS Monitoring Dashboard")

# with st.sidebar:
#     st.subheader("Controls")
#     # ìˆ˜ë™ ìƒˆë¡œê³ ì¹¨
#     if st.button("ğŸ”„ Refresh now"):
#         st.experimental_rerun()

#     # ìë™ ìƒˆë¡œê³ ì¹¨ ê°„ê²©(ì´ˆ). 0 = ë¹„í™œì„±í™”
#     auto_sec = st.number_input("Auto refresh every (sec)", min_value=0, max_value=300, value=0, step=5)

# # ìë™ ìƒˆë¡œê³ ì¹¨ íƒ€ì´ë¨¸
# if auto_sec and auto_sec > 0:
#     last = st.session_state.get("_last_refresh_ts", 0.0)
#     now = time.time()
#     if now - last >= auto_sec:
#         st.session_state["_last_refresh_ts"] = now
#         st.experimental_rerun()

# # -----------------------------
# # íƒ­ êµ¬ì„±
# # -----------------------------
# tab1, tab2, tab3 = st.tabs(["ğŸ“Š Dashboard", "ğŸ” Retrain", "ğŸ“š History"])

# # =========================================================
# # ğŸ“Š Dashboard íƒ­
# # =========================================================
# with tab1:
#     # ===== Realtime Charts (ìƒë‹¨) =====
#     st.subheader("Realtime Signals")

#     MAX_POINTS = int(os.getenv("REALTIME_MAX_POINTS", "5000"))
#     cols = table_columns("realtime_table")

#     need_cols = ["time_rms", "fft_over_env"]
#     missing = [c for c in need_cols if c not in cols]
#     if missing:
#         st.error(f"`realtime_table`ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing)}")
#     else:
#         # ì •ë ¬ í›„ë³´ ì¤‘ ì¡´ì¬í•˜ëŠ” ì²« ë²ˆì§¸ ì‚¬ìš©
#         sort_candidates = ["created_at", "id", "ts", "timestamp", "time", "dt", "seq", "offset"]
#         sort_col = next((c for c in sort_candidates if c in cols), None)

#         select_cols = []
#         if sort_col:
#             select_cols.append(f"`{sort_col}`")
#         select_cols += ["`time_rms`", "`fft_over_env`"]
#         select_sql = ", ".join(select_cols)

#         sql = f"SELECT {select_sql} FROM realtime_table "
#         if sort_col:
#             sql += f"ORDER BY `{sort_col}` ASC "
#         sql += f"LIMIT {MAX_POINTS};"

#         rows_rt = q(sql)
#         if not rows_rt:
#             st.info("realtime_table ë¹„ì–´ìˆìŒ")
#         else:
#             df_rt = pd.DataFrame(rows_rt)

#             # xì¶•: ì •ë ¬ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ê·¸ê±¸ë¡œ, ì—†ìœ¼ë©´ index
#             if sort_col and sort_col in df_rt.columns:
#                 x = df_rt[sort_col]
#             else:
#                 x = df_rt.index

#             # ìˆ«ìí™” & NaN ì œê±°
#             for c in ("time_rms", "fft_over_env"):
#                 df_rt[c] = pd.to_numeric(df_rt[c], errors="coerce")
#             df_rt = df_rt.dropna(subset=["time_rms", "fft_over_env"]).reset_index(drop=True)
#             if sort_col and sort_col in df_rt.columns:
#                 x = df_rt[sort_col]
#             else:
#                 x = df_rt.index

#             c1, c2 = st.columns(2)

#             # ì¢Œ: time_rms ì„ 
#             with c1:
#                 st.markdown("**time_rms**")
#                 fig1 = plt.figure(figsize=(6, 3))
#                 plt.plot(x, df_rt["time_rms"])
#                 plt.xlabel(sort_col or "index")
#                 plt.ylabel("time_rms")
#                 plt.tight_layout()
#                 st.pyplot(fig1)

#             # ìš°: fft_over_env ì½©ë‚˜ë¬¼(stem)
#             with c2:
#                 st.markdown("**fft_over_env**")
#                 fig2 = plt.figure(figsize=(6, 3))
#                 # í˜¸í™˜ ë²„ì „: use_line_collection ì¸ì ì—†ì´ í˜¸ì¶œ
#                 markerline, stemlines, baseline = plt.stem(x, df_rt["fft_over_env"])
#                 # ì½©ë‚˜ë¬¼ ëŠë‚Œ íŠœë‹ (ë²„ì „ë³„ ì†ì„± ìœ ë¬´ë¥¼ ëŒ€ë¹„í•´ try/except)
#                 try:
#                     markerline.set_marker('.')      # ë§ˆì»¤ ëª¨ì–‘
#                     markerline.set_markersize(3)    # ë§ˆì»¤ í¬ê¸°
#                     baseline.set_linewidth(0.5)     # ë² ì´ìŠ¤ë¼ì¸ ì–‡ê²Œ
#                     # stem ì„ ë„ ì•½ê°„ ì–‡ê²Œ
#                     try:
#                         for l in stemlines:
#                             l.set_linewidth(0.7)
#                     except TypeError:
#                         stemlines.set_linewidth(0.7)  # ì¼ë¶€ ë²„ì „ì—ì„  LineCollection ì•„ë‹˜
#                 except Exception:
#                     pass
#                 plt.xlabel(sort_col or "index")
#                 plt.ylabel("fft_over_env")
#                 plt.tight_layout()
#                 st.pyplot(fig2)

#     st.divider()

#     # ===== ìµœì‹  ISO / RAG ë‹µë³€ (í•˜ë‹¨ ì¹´ë“œ) =====
#     col1, col2 = st.columns(2)

#     with col1:
#         st.subheader("Latest ISO Advice")
#         rows = q("""
#             SELECT id, offset_idx, mae, suspect, query, result_markdown, created_at
#             FROM pms_ai_advice
#             ORDER BY id DESC
#             LIMIT 1;
#         """)
#         if rows:
#             r = rows[0]
#             st.caption(
#                 f"ID #{r['id']} Â· offset {r['offset_idx']} Â· "
#                 f"MAE {float(r['mae']):.3f} Â· {r.get('suspect') or '-'} Â· {r['created_at']}"
#             )
#             st.markdown(r.get("result_markdown") or "_(empty)_")
#         else:
#             st.info("No ISO advice yet.")

#     with col2:
#         st.subheader("Latest RAG Advice")
#         rows = q("""
#             SELECT id, offset_idx, mae, suspect, answer_md, created_at
#             FROM pms_ai_rag_advice
#             ORDER BY id DESC
#             LIMIT 1;
#         """)
#         if rows:
#             r = rows[0]
#             st.caption(
#                 f"ID #{r['id']} Â· offset {r['offset_idx']} Â· "
#                 f"MAE {float(r['mae']):.3f} Â· {r.get('suspect') or '-'} Â· {r['created_at']}"
#             )
#             st.markdown(r.get("answer_md") or "_(empty)_")
#         else:
#             st.info("No RAG advice yet.")

# # =========================================================
# # ğŸ” Retrain íƒ­
# # =========================================================
# with tab2:
#     st.subheader("Retrain Runs")

#     runs = q("""
#         SELECT id, started_at, ended_at, status, duration_sec, message
#         FROM pms_retrain_log
#         ORDER BY id DESC
#         LIMIT 20;
#     """)
#     df = pd.DataFrame(runs)
#     if not df.empty:
#         st.dataframe(df, use_container_width=True, hide_index=True)
#         sel = st.selectbox("Show details for log_id", df["id"].tolist())
#         if sel:
#             details = q("""
#                 SELECT seq, level, text, ts
#                 FROM pms_retrain_log_detail
#                 WHERE log_id=%s
#                 ORDER BY seq ASC;
#             """, (sel,))
#             st.write(f"### Log #{sel}")
#             for d in details:
#                 st.markdown(f"- `{d['ts']}` **{d['level']}** Â· {d['text']}")
#     else:
#         st.info("No retrain logs yet.")

#     st.divider()
#     st.caption("ìˆ˜ë™ ì¬í•™ìŠµ íŠ¸ë¦¬ê±° (FastAPIê°€ /retrain ì œê³µ ì¤‘ì¼ ë•Œ)")
#     api_url = os.getenv("API_RETRAIN_URL", "http://127.0.0.1:8001/retrain")
#     if st.button("Run Retrain via API"):
#         import requests
#         try:
#             r = requests.post(api_url, timeout=8)
#             st.success(f"Triggered: {r.status_code} {r.text[:300]}")
#         except Exception as e:
#             st.error(f"Trigger failed: {e}")

# # =========================================================
# # ğŸ“š History íƒ­
# # =========================================================
# with tab3:
#     st.subheader("ISO Advice History")
#     rows = q("""
#         SELECT id, offset_idx, mae, suspect,
#                LEFT(result_markdown, 140) AS preview,
#                created_at
#         FROM pms_ai_advice
#         ORDER BY id DESC
#         LIMIT 100;
#     """)
#     st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)

#     st.subheader("RAG Advice History")
#     rows = q("""
#         SELECT id, offset_idx, mae, suspect,
#                LEFT(answer_md, 140) AS preview,
#                created_at
#         FROM pms_ai_rag_advice
#         ORDER BY id DESC
#         LIMIT 100;
#     """)
#     st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)